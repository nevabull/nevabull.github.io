<!DOCTYPE html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Neva's Blog</title>
    <!-- CSS only -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">
    <!-- JavaScript Bundle with Popper -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
 
</head>
<body>
    
    
     <!---  <p id="output">Stuff on the side</p>--> 
     <nav class="navbar navbar-expand-lg navbar-light" style="background-color: #e3f2fd;">
        <!-- Navbar content -->
        <div class="container-fluid">
            <a class="navbar-brand" href="./index.html">Neva Bull</a>
            <button title="Navigation menu" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation" >
            <span class="navbar-toggler-icon"></span>
            </button>
            
        <div class="collapse navbar-collapse"  id="navbarNav">
            <div class="navbar-nav">
        
                
                <a class="nav-link active" href="./index.html" aria-current="true">machine learning</a>
                <a class="nav-link" href="#">image processing</a>
                <a class="nav-link" href="#">neuroscience</a>
            </div> 
        </div>   
        </div>
     
     </nav>
     
     <div class="row">
        <div class="col-sm-1"> <!----style="background-color: #e3ecf1;">-->
        </div>
        <div class="col-sm-1">

        </div>
        <div class="col-sm-8">

            <div class="container-fluid">
                <div class = "row">
                    <br/>
                    <br/>
                </div>   
    <h4 class="display-6">Getting Rich Quick with Horse Racing - Part 2</h4>
<br/>
    <h4>Variables</h4>
    <p>If you are a developer, when you think of types of variables, you probably think of things like: int, long, bool, object etc.  
        In statistics, which is fundamental to ML, variables are thought of more in terms of whether they are:  </p>
        <ul>
            <li>Continuous: 
                <p>- A number where the size of the number has relative meaning. For example height, 186cm tall is taller than 185.99cm.</p></li>
            <p>- Discreet variables are similar to continuous, but there are finite possabilities. This means they can be counted and have <em>frequencies</em>. For example, number of people with heart disease.</p>           
            <li>Categorical</li>
            <p>- Nominal categorical variables are discreet, They can be counted into frequencies, but it doesn't make sense to add them up. For example: names of colours could be: red, blue, green etc. 
                Categorical variables are often arbitarily coded into integers with something like red = 1, blue = 2 etc.
                It would make no sense in this case to take the average or sum of colours as the value of the integers used for coding have no relative meaning. </p>
            <p>- Ordinal categorical variables are variables where the value of the category do have a relative meaning, e.g, weight could be categorised as: underweight = 1, normal = 2, overweight = 3 or obese = 4.</p>
        </ul>
<br/>  
     <p>For ML, generally we need to get all our variables into one vector of float. 
        For that we do some transforms like normalising continuous, discreet and ordinal variables and One Hot Encoding nominal variables.</p>
        <p>Normalisation is just transforming the variable into a float so that the maximum value becomes 1 and the other values are their relative fraction of the maximum. 
        This can also be done such that the minimum becomes 0. ML.NET comes with methods that do this for you. Check out the <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.normalizationcatalog?view=ml-dotnet-2.0.0">NormalizationCatalog Class.</a> </p>
        <p>One Hot Encoding, splits a single variable into seperate dichotomous variables for each category: 
            for example, if you have a variable for colour with values of red, green or blue it will become three dichotomous variables (one for each colour with values of only 0 or 1).</p>

       <h4>Data Structure</h4>
       <p>For categorization tasks where you have a lot of examples of things (i.e. individual horses) and you want to predict some feature of them (i.e. winner or looser) 
        you need to have the data structured such that <em><strong>1 row is 1 example.</strong></em> It's a good idea to have this in mind when you collect your data.</p>  
        <p>For supervised ML you need to include the feature you want to predict as the 'ground truth' or 'label'. So in our example we will have a dichotomous variable (nominal with only two possabilities) - Winner or Looser.
            We will get this from looking at past horse races, collecting information about each horse along with whether it was a winner or looser. 
        </p> 
        <p>
            There is a large set of possible information about horses in a race we could collect, but for the sake of this example we will keep it simple by only collecting the following:
        </p>
        <p>Winner or Looser, history (positions over the last 10 races), total prize money won, percent of races won and percent of races placed in top 3.</p> 
        <p><strong>Comparing Apples With Apples</strong></p> 
        <p>We immediately have a problem with this data structure. All races are not equal. Some races are for very successful horses and have large prize money and some are less so. Some are for experienced horses and some are for newcomers</p>
        <p>So we need a way to compare horses within each race - a way to find the best horse out of the set in the race. One way to do this is to normalise the continous variables within each race.
           This will result in a relative measure of each of our continuous variables in every row. 
        </p>
        <p>The data for a race will end up looking like this:</p>
<pre>
Winner  ID      History         Money           WinPcnt                 PlacePcnt
false	1	70x88x45x7	0.359375	0.681818181818182	0.414519906323185
false	2	56x71x5603	0.3125	        0.613636363636364	0.44847775175644
false	3	1713332x76	0.546875	0.738636363636364	1
false	4	2x4516x304	0.5	        0.715909090909091	0.400468384074941
false	5	31541x0000	0.328125	0.477272727272727	0.675644028103044
true	6	111124x2x1	1	        0.931818181818182	0.250585480093677
false	7	1325110269	0.296875	0.477272727272727	0.398126463700234
false	8	4440x70125	0.390625	0.511363636363636	0.168618266978923
false	9	41535558x8	0.203125	0.454545454545455	0.546838407494145
false	10	42113x1112	0.984375	1	                0.5
</pre>
<p>Then we just append all races into one big long list of rows where each row is one horse. The ID column is the number the horse is assigned in the race. 
    This number is picked at random - it does not add information regarding if the horse will win, therefore it will not be included in training. We keep it, as we can use it later to identify horses predicted to win or loose.</p>
    <p>Now we have our data together, let's write some code and do some training in <a href="./ml3.html">Part 3</a></p>
</div>
</div>
</div>
</body>

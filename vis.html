<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Neva's Blog</title>
    <!-- CSS only -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">
    <!-- JavaScript Bundle with Popper -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
 
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-light" style="background-color: #e3f2fd;">
        <!-- Navbar content -->
        <div class="container-fluid">
            <a class="navbar-brand" href="./index.html">Neva Bull</a>
            <button title="Navigation menu" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation" >
            <span class="navbar-toggler-icon"></span>
            </button>
            
        <div class="collapse navbar-collapse"  id="navbarNav">
            <div class="navbar-nav">
                <a class="nav-link active" href="./vis.html">Computational Neuroscience</a>
                <a class="nav-link " href="./ml1.html" aria-current="true">Machine Learning</a>
            </div> 
        </div>   
        </div>     
     </nav>
     <div class="row">
        <div class="col-sm-1"> <!----style="background-color: #e3ecf1;">-->
        </div>
        <div class="col-sm-1">

        </div>
        <div class="col-sm-8">

            <div class="container-fluid">
                <div class = "row">
                    <br/>
                    <br/>
                </div>     
     <br/>
     <h4 class="display-6">A simple computational simulation of the retina</h4>
     <br/>
     <h5>Why try to simulate the retina?</h5>
     <p>There is ongoing debate about what the fundamental mechanism of computation by excitable cells is.  To use analogy, think of the computer you are reading this on. 
        It's likely a digital computer that does logical operations on sequences of bits. 
        Because we invented them, we know for sure that this is achieved by transistors implementing logic gates to manipulate bits. So the information <em>encoded</em> as series of bits (i.e. 00110010) 
        and is <em>processed</em> through a small set of logical operations that transistors can do. How the brain encodes and processes information is still a mystery.</p> 
     <p>Vision is a good place to start, because we can use an objectively measurable input (an image) and objectively measure the output.  
        The reason to use computational simulation is that it may produce surprising results. Traditional mathematical modelling can accurately describe relationships between inputs and outputs, 
        but this doesn't mean that the cells are doing the math as described in these models. if they are doing math, what sort is it and how do they achieve it?</p> 
        <br/>
     <h5>Basic Concepts</h5>
                <ul>
                    <li><u>Repetition in cortical circuitry</u></li>
                    <p>There appears to be replication of a basic architecture throughout the cortex. The classic example is the cortical column consisting of 6 layers of interconnected neurons.</p>
                    <li><u>Receptive Fields</u></li>
                    <p>
                    Throughout the visual system, from the retina through to occipital, temporal and parietal cortex there is a repeating pattern of what are known as 'receptive fields'. 
                    These are cortical representations of space with some feature in the center being contrasted with the surround. They can represent various sizes in terms of visual angle (i.e. how big a bit of retina it maps to). 
                     They also represent various differences between center and surround (i.e. simple differences in brightness/colour, orientations of lines, motion vectors etc)</p>
                     <li><u>Behaviours of neurons that can encode information</u></li>
                     <p>Neurons (and other excitable cells) can do at least two things to convey information to the cells they are connected to:</p>
                     <ol>
                        <li><u>They can change their firing rate (frequency).</u></li>
                        <p>Neurons are said to 'fire' (or spike) when they have an action potential. This is a sudden rapid change in the electical polarity of the cell that triggers release of substances that influence neighbouring cells.
                        Some of these are called 'neurotransmitters'.
                        </p>
                        <p>
                            Cells have internal mechanisms regulating their firing rate which can vary between cell types. The firing rate has an upper limit determined by the cells refractory period. 
                            Some cells fire at predictable regular intervals (pacemaker cells), but for many the firing rate is erratic and best described by probabilities.
                        </p>
                        <li><u>They can modulate the amplitude of the signal (inhibition or excitation) they send to their connections.</u></li>
                        <p>There are hundreds of different neurtransmitters, co-transmitters and neuromodulators. Many of these bind to multiple recepetors each having unique effects on their cell.
                            The absurd complexity doesn't end there, and the more I study it the more terrifying it gets.                                                      
                        </p>
                        <p>
                            Thankfully, this complexity can be reduced to a simple rule; <em>All communications from a cell (the efferent) lead to either inhibition or excitation of the receiving cell (the afferent).</em> 
                            This changes the likelihood of the receiving cell firing. It can be mediatiated by all sorts of mechanisms, but the end result is the same - the cell will either be primed to be more likely to fire if it receives excitation, 
                            or made less likely to fire if it receives inhibition. The effect can happen over a range of time scales, last for varying durations and occur between cells of varying physical distance from each other.       
                        </p>
                     </ol>
                     <li><u>The retina is part of the brain</u></li>
                     <p>The cells in the retina are not confined to simple photoreceptors, there are numerous layers of different cell types, all doing lots of information processing.
                        The signals that go down the optic nerve have already been extensively processed.
                    The retina can be thought of as a part of the brain, just out on stalks looking at the world.</p>
                    <li><u>What you 'see' is not what is really out there.</u></li>
                    <p>The visual system comprises the retina, some sub-cortical areas and a very large part of the cortex. It's most of the back half of the brain, plus some bits in the middle and front. 
                        By the time an image materialises into conscious perception it has been extensively manipulated by all these cells. We see a rendition rather than reality.</p>
                </ul>
     
     
     <br/>
     <h4>The Simulation Architecture</h4>
     <br/>
     <p>
     To keep things as simple as reasonably possible I have included only 3 layers of cells.  These are loosely based on their physiologic name-sakes and include:
    </p><p>
     <ul>
        <li>Cones</li>
        <p>These are the photoreceptors that recieve information from the input image</p>
        <li>Horizontal Cells</li>
        <p>These aggregate the responses of the cones into center-surround receptive fields.</p>
        <li>Ganglion Cells</li>
        <p>These aggregate responses of Horizontal cells into center-surround receptive fields. Their resultant firing rate forms the output of the simulation.</p>
     </ul>     
    </p>
<p>
    Images are two dimmensional arrays (x pixels wide and y pixels high) of pixels that have varying colour. In this model there is one cone, one horizontal and one ganglion cell for every pixel in the image. There are, however, many connections between these cells.  
    All possible sets of 9 adjacent cones ( 3 x 3 grids ) are connected to each horizontal cell and all possible sets of 9 adjacent horizontal cells are connected to each ganglion cell.
    As a result, for an image of 200 x 200 pixels there will be 120,000 virtual neurons and 720,000 synapses.   
</p>
<p><u>Schematic of single receptive field made up of cones:</u></p>
<p>E stands for excitatory - these cells send excitatory signals to the cells they are connected to.  I stands for Inhibitory</p>
<p><img src="./images/cones1.png" alt="receptive field schematic"/></p>
<p><u>Schematic of multiple receptive fields (only one dimension displayed for simplicity):</u></p>
<p><img src="./images/conearray.png" alt="array of receptive fields"/></p>
<p><u>This architecture is repeated for horizontal cells</u></p>
<p><img src="./images/horzl.png"/></p>
<br/>
<br/>
<h4>Properties and behaviours of simulated cells</h4>
<br/>
<ol>
    <li><u>Common Properties:</u></li>
    <p>
        <ul>
            <li>
               <p>
                    Cells have a difference in electrical potential - measured in mV - across the cell membrane (between the intracellular and extracellular space).  
                    This can change either up or down. If the potential reaches a 'critical' potential the cell will 'fire' and then immediately return it's potential to a 'resting' potential.
                    When a cell fires it changes the potential of the cells it is connected to in either a positive or negative direction (inhibition or excitation).
               </p> 
               <p>
                  Each cell is an independant object. They maintain their current status ( membrane potential and internal timer ) and their individual properties in isolation.
                  They are created individually and begin firing autonomously. The timining of each cell creation is not tightly controlled and hence has a degree of randomness. 
                  This results asynchronous firing of cells even if they are created with the same properties.
                   e.g. adjacent cones stimulated by pixels of the same brightness are unlikely to fire at the same time.      
               </p>
              
            </li>
        </ul>    
    </p>
    <li>        
        <u>Properties of Cones</u>
        <p>
            Cones have a fast basal firing rate and are inhibited by the level of brightness of the light hitting them (i.e. the brightness of the corresponding pixel in the input image). 
            In other words, cones that are stimulated by a bright pixel will fire at a slower rate than one's stimulated by a dark pixel.
        </p>
        <p>
            This sounds backwards - but I found, accidently, that it is required. 
            When documenting my working code, I saw that I had a minus where there should have been a plus, so I reveresed it and the simulation no longer produced sensible output.
            I went back to the physiology textbooks and found that this is indeed the behaviour of real cones!
        </p>
        <p>
            Each cone spontaneously excites itself by a small amount at a rate determined by the brightness of its pixel. 
             This is in milliseconds, a pixel with a bightness of 200, will result in the cell raising it's membrance potential every 200ms. 
             When this excitation reaches the critical threshold, it will fire and send a packet of inhibition or excitation to the horizontal cells it is connected to.         
            This results in cones stimulated by bright pixels firing at slower rates than those responding to dark pixels. 
        </p>
        <p>           
            The degree of excitation sent by the cone (e) to the horizontal cell in the center of the receptive field is determined by the brightness of it's pixel. The brighter the pixel the larger the excitation. 
            The relationship is linear in a direct mapping of the pixel brightness (range: 0 = black - 255 = white). 
        </p>
        <p>
            The inhibitory signal sent by a cone (i) to the horizontal cells in the surround section of the receptive field is: -e/8.   
        </p>        
    </li>
    <li>
        <u>Properties of Horizontal Cells</u>
        <p>
            Horizontal cells do not spontaneously polarise themselves. They do not run an internal timer. 
            They receive packets of inhibition and excitation from cones. If and when the received packets sum above the critical threshold the cell will fire and send packets upstream to the gangion cells.
            The cell then resets it's potential back to the resting potential.  
        </p>
        <p>They polarise their respective ganglion cells by +1 mV for excitation and -8 mV for inhibition.</p>
        
    </li>
    <li><u>Properties of Ganglion Cells</u></li>
    <p>The output image is determined by the sum of the number of times each ganglion cell has fired. The pixel in the ouput image corresponding to the location of the ganglion cell is made brighter each time it fires.
        The ouput image evolves as the simulation runs with pixels becoming progressively brighter with every spike of a ganglion cell.</p>
        <p> <strong>Therefore, the output image is a representation of the firing rate of ganglion cells accross both space and time. </strong></p> 
    <p> 
         Ganglion cells spontaneously depolarise themselves by an amount on the tick of an internal timer. This has the effect of reducing noise and hence increasing the signal to noise ratio (SNR).     
     </p>
     <p>
        Ganglion cells are self regulating.  They have 3 mechanisms for this: 
        <ol>
            <li><u>Changing the time interval between spontaneous depolarisations</u></li>
            <li><u>Changing the amount of each depolarisation</u>
            <li><u>Changing their critical voltage threshold for firing.</u></li>
        </ol> </p>
        <p>
        Each of these is non-linear, in that they are doubled or halved at each change. <br/><br/>
        The effects balance each other out and result in retention of all 'information' (in this example, the information refers to local changes in brightness of pixels) in the image. <br/>
        This results in edges of any contrast gradient being detected.  The 'strength' of the signal - corresponding to the degree of intensity gradient - is encoded in the temporal dynamics of the ganglion cell. <br/><br/>
        Strong edges will immerge quickly with a rapid initial burst of ganglion cell spiking. These will downregulate proportionately relative to the intensity of initial firing. 
        As this is happening, less intensly stimulated ganglion cells will become increasing primed and hence their firing rate will begin to increase.<br/><br/>
        The result is that distinct edges will emerge first, but over time increasingly less distinct edges will emerge.<br/>
        <p>
        It is important to note, that this is not the end of information processing in the visual cortex, rather these signals are being sent upstream in real time.  
        So the effect on vision is that bold edges are detected fast and passed upstream <em>before</em> subtle edges. 
        This is why if you glance very briefly at something, you will only detect the bold edges. To see subtle edges you have to stare for a bit.    
    </p>   
    </p>
</ol>
<h4>Results</h4>
<p><strong>The classic Lena image - the video starts with the end result - to see it evolve, hit play</strong></p>
<video controls="controls" src="./images/Lena2.mp4" type="video/mp4" autoplay loop width="900">
    <p>Try using a browser that supports emedded video -like Edge</p>
    </video>
</video>
<br/><br/><br/>
<p><strong>An image with a large range of contrast gradients</strong></p>
<video controls="controls" src="./images/Lake1.mp4" type="video/mp4" autoplay loop width="900">
    <p>Try using a browser that supports emedded video -like Edge</p>
    </video>
    <br/>
    <br/>
<p>
   The firing rate of ganglion cells can be seen as encoding edges along with their relative strengths. It does not saturate with prolonged runs of the simulation.
   By that I mean, edges defined by low contrast gradients never end up depicted as bright as high intensity gradients.  
   This can be seen by the difference between the shirt stripes and the clouds in the above image. 
   The strips are the first to appear, whilst the distant water and clouds are emerging, subtle edges in the stripes are becoming apparent.   
</p>
<p>
    This is mediated by independant adaptation of each ganglion cell. The result of this adaptation is that no assumptions or prior knowledge is needed to find all edges in any image. 
    It will work independant on the properties of the input image - without needing tweeking.  
</p>
<p>
    <h4>Importance of Time and Temporal Correlation</h4>
</p>
<p>
   We can see that excitation is built up by summing the inputs from cells in the previous layers. There is a small component of random noise in the outputs of the simulation and no two runs are identical.
   This is because each cell is running an independant timer with it's own duration. Even when adjacent cells have timers with the same duration, they are unlikely to have been initiated at exactly the same time. 
   When cells are aggregating inputs from the previous layer, there is a chance that sufficient excitatory signals will be received to trigger a spike before sufficient inhibition has been received.   
   This results in a small amount of noise in the output - visible by feint random dots.  
</p>
<p>
    There is a dependency on a temporal correlation between incoming signals from the proceeding cell layer. 
    They don't need to be simulataneous, but the strength of the resultant summation is determined by how close they are together in time. i.e. the degree of synchronicity. 
    This is because the cells are rebalancing themselves back to the resting potential (and adapting their propensity to spike) after each spike.  
</p>
<p>
    This has implications for signal detection.  
    If the visual system is aggregating information in this fashion then it would follow that <em>a large number of synchronous low intensity signals will produce the same effect as a small number of synchronous high intensity signals</em>.
    This was the basic idea behind the experiments in our 2003 paper: 
    <a href="https://journals.sagepub.com/doi/10.1068/p3278?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%20%200pubmed">Bull NJ, Hunter M, Finlay DC. Cue gradient and cue density interact in the detection and recognition of objects defined by motion, contrast, or texture. Perception. 2003;32(1):29-39.</a> 
</p>
<p>In that paper we demonstrated that this simple rule applies irrespective of whether the information in question is a difference in brightness, velocity or shapes.</p>
</div>
</div>
</div>
</body>
</html>